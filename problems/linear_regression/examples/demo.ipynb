{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Toolkit - Demo Notebook\n",
    "\n",
    "This notebook demonstrates the Linear Regression toolkit with three experiments:\n",
    "1. **Straight Line with Noise** - Basic linear regression\n",
    "2. **Collinearity and Ridge Regularization** - Effect of L2 regularization\n",
    "3. **Polynomial Regression** - Comparing different polynomial degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from linear_models import LinearRegressionClosedForm\n",
    "from metrics import mse, r2_score\n",
    "from selection import train_test_split\n",
    "from plotting import plot_predictions, plot_residuals, plot_fitted_curve\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Experiment 1: Straight Line with Noise\n",
    "\n",
    "**Goal:** Demonstrate basic linear regression on data generated from y = 3 + 2x + ε"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1: Straight Line with Noise\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate synthetic data: y = 3 + 2x + ε\n",
    "n_samples = 200\n",
    "X = np.random.uniform(0, 10, n_samples).reshape(-1, 1)\n",
    "epsilon = np.random.randn(n_samples) * 1.0  # Noise with std=1\n",
    "y = 3 + 2 * X.flatten() + epsilon\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionClosedForm(fit_intercept=True, alpha=0.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nTrue parameters: intercept=3.0, slope=2.0\")\n",
    "print(f\"Learned parameters: intercept={model.intercept_:.4f}, slope={model.coef_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_mse = mse(y_train, y_train_pred)\n",
    "test_mse = mse(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTraining MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(y_test, y_test_pred, title=\"Experiment 1: Predictions vs True Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fitted_curve(X_test, y_test, y_test_pred, title=\"Experiment 1: Fitted Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Experiment 2: Collinearity and Ridge Regularization\n",
    "\n",
    "**Goal:** Demonstrate how Ridge regularization affects coefficient magnitude when features are highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Collinear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 2: Collinearity and Ridge Regularization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_samples = 100\n",
    "x1 = np.random.randn(n_samples)\n",
    "x2 = x1 + 0.01 * np.random.randn(n_samples)  # Highly correlated with x1\n",
    "X = np.column_stack([x1, x2])\n",
    "y = 3 * x1 + 2 * x2 + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nFeature correlation: {np.corrcoef(x1, x2)[0, 1]:.4f}\")\n",
    "print(f\"(Close to 1.0 indicates high collinearity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Alpha Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0, 1e-3, 1e-2, 1e-1, 1.0]\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(f\"{'Alpha':<10} {'Test MSE':<12} {'||coef||₂':<12} {'Coefficients'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = LinearRegressionClosedForm(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mse_val = mse(y_test, y_test_pred)\n",
    "    coef_norm = np.linalg.norm(model.coef_)\n",
    "    \n",
    "    results.append({\n",
    "        'alpha': alpha,\n",
    "        'test_mse': test_mse_val,\n",
    "        'coef_norm': coef_norm,\n",
    "        'coef_': model.coef_.copy()\n",
    "    })\n",
    "    \n",
    "    print(f\"{alpha:<10.4f} {test_mse_val:<12.4f} {coef_norm:<12.4f} {model.coef_}\")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Impact of Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot MSE vs alpha\n",
    "axes[0].plot([r['alpha'] for r in results], [r['test_mse'] for r in results], 'o-', markersize=8)\n",
    "axes[0].set_xlabel('Alpha (Regularization Strength)', fontsize=12)\n",
    "axes[0].set_ylabel('Test MSE', fontsize=12)\n",
    "axes[0].set_title('Test MSE vs Regularization', fontsize=14)\n",
    "axes[0].set_xscale('symlog', linthresh=1e-4)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot coefficient norm vs alpha\n",
    "axes[1].plot([r['alpha'] for r in results[1:]], [r['coef_norm'] for r in results[1:]], 'o-', markersize=8, color='red')\n",
    "axes[1].set_xlabel('Alpha (Regularization Strength)', fontsize=12)\n",
    "axes[1].set_ylabel('||coef||₂', fontsize=12)\n",
    "axes[1].set_title('Coefficient Norm vs Regularization', fontsize=14)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion - Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "As alpha (regularization strength) increases:\n",
    "\n",
    "1. **Coefficient Magnitude Decreases**: The L2 norm of the coefficient vector shrinks consistently. Ridge regression penalizes large coefficients, forcing them toward zero but never exactly zero.\n",
    "\n",
    "2. **Bias-Variance Tradeoff**: With collinear features, OLS (alpha=0) produces unstable coefficient estimates with high variance. Ridge regression introduces bias but reduces variance, often improving generalization.\n",
    "\n",
    "3. **Test MSE Pattern**: Initially, small amounts of regularization may reduce test MSE by preventing overfitting. However, excessive regularization (large alpha) increases bias too much, degrading performance.\n",
    "\n",
    "4. **Practical Insight**: When features are highly correlated, Ridge regression distributes weights more evenly between them rather than arbitrarily assigning all weight to one feature.\n",
    "\n",
    "**Key Takeaway**: Ridge regularization is particularly effective when dealing with multicollinearity in your features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Experiment 3: Polynomial Regression\n",
    "\n",
    "**Goal:** Compare linear regression with different polynomial degrees to fit nonlinear data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Nonlinear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 3: Polynomial Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_samples = 150\n",
    "X_raw = np.random.uniform(-3, 3, n_samples)\n",
    "epsilon = np.random.randn(n_samples) * 0.5\n",
    "y = 1 + 2 * X_raw - 0.3 * X_raw**2 + epsilon\n",
    "\n",
    "# Sort for plotting\n",
    "sort_idx = np.argsort(X_raw)\n",
    "X_raw = X_raw[sort_idx]\n",
    "y = y[sort_idx]\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw.reshape(-1, 1), y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrue function: y = 1 + 2x - 0.3x²\")\n",
    "print(f\"Training samples: {len(X_train_raw)}\")\n",
    "print(f\"Test samples: {len(X_test_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, degree):\n",
    "    \"\"\"\n",
    "    Create polynomial features up to specified degree.\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Input features, shape (n_samples, 1)\n",
    "        degree (int): Maximum polynomial degree\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Polynomial features, shape (n_samples, degree)\n",
    "    \"\"\"\n",
    "    X = X.flatten()\n",
    "    features = np.column_stack([X**d for d in range(1, degree + 1)])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Polynomial Degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 2, 5]\n",
    "models = {}\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "\n",
    "for deg in degrees:\n",
    "    print(f\"\\n--- Degree {deg} ---\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    X_train_poly = polynomial_features(X_train_raw, deg)\n",
    "    X_test_poly = polynomial_features(X_test_raw, deg)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegressionClosedForm(alpha=0.0)\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    models[deg] = model\n",
    "    \n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train_poly)\n",
    "    y_test_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    train_mse_val = mse(y_train, y_train_pred)\n",
    "    test_mse_val = mse(y_test, y_test_pred)\n",
    "    train_r2_val = r2_score(y_train, y_train_pred)\n",
    "    test_r2_val = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Training MSE: {train_mse_val:.4f}, R²: {train_r2_val:.4f}\")\n",
    "    print(f\"Test MSE: {test_mse_val:.4f}, R²: {test_r2_val:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Fitted Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-3, 3, 300).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X_raw, y, alpha=0.5, s=20, label='True Data', edgecolors='k')\n",
    "\n",
    "colors = ['green', 'blue', 'red']\n",
    "for deg, color in zip(degrees, colors):\n",
    "    X_plot_poly = polynomial_features(X_plot, deg)\n",
    "    y_plot_pred = models[deg].predict(X_plot_poly)\n",
    "    plt.plot(X_plot, y_plot_pred, color=color, lw=2, label=f'Degree {deg}')\n",
    "\n",
    "# Plot true function\n",
    "y_true_plot = 1 + 2 * X_plot.flatten() - 0.3 * X_plot.flatten()**2\n",
    "plt.plot(X_plot, y_true_plot, 'k--', lw=2, alpha=0.7, label='True Function')\n",
    "\n",
    "plt.xlabel('X', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Polynomial Regression: Comparing Degrees', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion - Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which degree fits best and why?\n",
    "\n",
    "**Degree 1 (Linear)**: Underfits the data because the true relationship is quadratic. The linear model cannot capture the curvature, resulting in higher MSE and lower R².\n",
    "\n",
    "**Degree 2 (Quadratic)**: **Best fit!** This matches the true data-generating process (y = 1 + 2x - 0.3x²). It captures the curvature accurately without overfitting, achieving the lowest test MSE and highest R².\n",
    "\n",
    "**Degree 5 (Quintic)**: Overfits the training data. While it achieves low training MSE, it captures noise rather than the underlying pattern. The model shows wiggly behavior outside the training range and has higher test MSE than degree 2.\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "Model complexity should match the complexity of the underlying process:\n",
    "- **Too simple** (degree 1) misses important patterns\n",
    "- **Too complex** (degree 5) fits noise instead of signal\n",
    "- **Just right** (degree 2) captures the true relationship\n",
    "\n",
    "Cross-validation or holdout validation (as done here) helps identify the right complexity level.\n",
    "\n",
    "**Practical Takeaway**: Start with simpler models and increase complexity only when justified by improved test performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "This notebook demonstrated three important aspects of linear regression:\n",
    "\n",
    "1. **Basic Linear Regression**: Successfully recovered true parameters from noisy data\n",
    "2. **Ridge Regularization**: Showed how L2 penalty helps with collinear features\n",
    "3. **Polynomial Features**: Illustrated the bias-variance tradeoff and model complexity\n",
    "\n",
    "All experiments used our custom `LinearRegressionClosedForm` implementation with the closed-form normal equation solution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
